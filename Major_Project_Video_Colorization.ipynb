{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq6exNyp-Mbm"
      },
      "source": [
        "#Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGnd4Wr7CFar"
      },
      "outputs": [],
      "source": [
        "#DAVIS Dataset\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "path = kagglehub.dataset_download(\"mengzj/davis-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfAJimI19uzL"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "DATASET_PATH = \"/root/.cache/kagglehub/datasets/mengzj/davis-data/versions/1/DAVIS/JPEGImages/480p\"\n",
        "OUTPUT_COLOR_PATH = \"dataset/color/\"\n",
        "OUTPUT_BW_PATH = \"dataset/bw/\"\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def extract_frames():\n",
        "    os.makedirs(OUTPUT_COLOR_PATH, exist_ok=True)\n",
        "    os.makedirs(OUTPUT_BW_PATH, exist_ok=True)\n",
        "\n",
        "    video_folders = sorted(os.listdir(DATASET_PATH))\n",
        "\n",
        "    for video in tqdm(video_folders, desc=\"Processing Videos\"):\n",
        "        video_path = os.path.join(DATASET_PATH, video)\n",
        "        frame_files = sorted(os.listdir(video_path))\n",
        "        frames=0\n",
        "\n",
        "        for i, frame_name in enumerate(frame_files):\n",
        "            frame_path = os.path.join(video_path, frame_name)\n",
        "            frame = cv2.imread(frame_path)\n",
        "\n",
        "            if frame is None:\n",
        "                continue\n",
        "\n",
        "            frame = cv2.resize(frame, IMG_SIZE)\n",
        "\n",
        "            # Save color frame\n",
        "            color_save_path = os.path.join(OUTPUT_COLOR_PATH, f\"{video}_{i}.png\")\n",
        "            cv2.imwrite(color_save_path, frame)\n",
        "\n",
        "            # Convert to grayscale and save\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            bw_save_path = os.path.join(OUTPUT_BW_PATH, f\"{video}_{i}.png\")\n",
        "            cv2.imwrite(bw_save_path, gray_frame)\n",
        "\n",
        "            frames += 1\n",
        "            if frames==100:\n",
        "              break\n",
        "\n",
        "    print(f\"Dataset prepared {len(os.listdir(OUTPUT_COLOR_PATH))} frames extracted.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    extract_frames()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1CEYMbj-UM7"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "#Model Colorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48Mj6bb6-k-W"
      },
      "source": [
        "#Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B12MILjsgBrD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "#from colorization_model import build_colorization_model\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Paths\n",
        "BW_PATH = \"dataset/bw/\"\n",
        "COLOR_PATH = \"dataset/color/\"\n",
        "MODEL_PATH = \"colorization_300.keras\"\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "# Load dataset\n",
        "def load_dataset():\n",
        "    bw_images, color_images = [], []\n",
        "\n",
        "    file_names = sorted(os.listdir(BW_PATH))\n",
        "\n",
        "    for file in tqdm(file_names, desc=\"Loading Frames\"):\n",
        "        bw_img = cv2.imread(os.path.join(BW_PATH, file), cv2.IMREAD_GRAYSCALE)\n",
        "        color_img = cv2.imread(os.path.join(COLOR_PATH, file))\n",
        "\n",
        "        if bw_img is None or color_img is None:\n",
        "            continue\n",
        "\n",
        "        bw_img = cv2.resize(bw_img, IMG_SIZE) / 255.0\n",
        "        color_img = cv2.resize(color_img, IMG_SIZE) / 255.0\n",
        "\n",
        "        bw_images.append(img_to_array(bw_img).reshape(128, 128, 1))  # Gray input\n",
        "        color_images.append(img_to_array(color_img))  # RGB output\n",
        "\n",
        "    return np.array(bw_images), np.array(color_images)\n",
        "\n",
        "# Train model\n",
        "#def train_and_save_model(epochs=10, batch_size=32):\n",
        "X_train, Y_train = load_dataset()\n",
        "print(f\"Loaded {len(X_train)} frames for training.\\nStarting Training...\")\n",
        "model = build_colorization_model()\n",
        "history = model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
        "\n",
        "model.save(MODEL_PATH)\n",
        "print(f\"Model saved at {MODEL_PATH}\")\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "  #  train_and_save_model(epochs=50,batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLGK5Lbb-2_v"
      },
      "source": [
        "#Video Colorization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "K-zvHXc426nV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK3nwEWl-T2c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "def build_colorization_model(input_shape=(128, 128, 1)):\n",
        "    model = models.Sequential([\n",
        "        # Encoder\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "\n",
        "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        layers.AveragePooling2D((2, 2)),\n",
        "\n",
        "        # Bottleneck\n",
        "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "\n",
        "        # Decoder\n",
        "        layers.Conv2DTranspose(256, (3, 3), strides=2, activation='relu', padding='same'),\n",
        "        layers.Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same'),\n",
        "        layers.Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same'),\n",
        "\n",
        "        layers.Conv2D(3, (3, 3), activation='tanh', padding='same')  # Output: 3 color channels\n",
        "    ])\n",
        "\n",
        "    optimizer = Nadam(learning_rate=0.0001)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=MeanSquaredError(), metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BcViidV-52B"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "# Paths\n",
        "MODEL_PATH = \"colorization_300.keras\"\n",
        "INPUT_VIDEO = \"bw_4.mp4\"\n",
        "OUTPUT_VIDEO = \"colorized_video.mp4\"\n",
        "\n",
        "IMG_SIZE = (512, 512)  # Corrected to match training image size (128x128)\n",
        "\n",
        "# Load the model with the correct loss function\n",
        "custom_objects = {\"mse\": MeanSquaredError()}\n",
        "model = tf.keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)\n",
        "\n",
        "def process_video():\n",
        "    cap = cv2.VideoCapture(INPUT_VIDEO)\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    out = cv2.VideoWriter(OUTPUT_VIDEO, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Step 1: Convert input frame to grayscale\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Step 2: Resize to model input size\n",
        "        gray_frame_resized = cv2.resize(gray_frame, IMG_SIZE) / 255.0\n",
        "        gray_frame_resized = img_to_array(gray_frame_resized).reshape(1, 512, 512, 1)\n",
        "\n",
        "        # Step 3: Predict color frame\n",
        "        color_frame = model.predict(gray_frame_resized)[0]\n",
        "        color_frame = (color_frame * 255).astype(np.uint8)  # Bring back to [0,255]\n",
        "\n",
        "        # Step 4: Resize predicted frame back to original frame size\n",
        "        color_frame = cv2.resize(color_frame, (width, height))\n",
        "\n",
        "        # Step 5: Save frame\n",
        "        out.write(color_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "        print(f\"Processed frame {frame_count}\")\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Video colorization completed: {OUTPUT_VIDEO}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_video()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deployment (For Images)"
      ],
      "metadata": {
        "id": "uwwHHbuQ9vAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n",
        "\n",
        "import gradio as gr\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load trained model\n",
        "\n",
        "model = tf.keras.models.load_model(\"colorization_300.keras\", custom_objects={\"mse\": tf.keras.losses.MeanSquaredError()})\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def colorize_image(input_img):\n",
        "# Convert image to grayscale\n",
        "gray = cv2.cvtColor(input_img, cv2.COLOR_RGB2GRAY)\n",
        "gray = cv2.resize(gray, IMG_SIZE)\n",
        "gray_input = gray.astype(\"float32\") / 255.0\n",
        "gray_input = img_to_array(gray_input).reshape(1, 128, 128, 1)\n",
        "\n",
        "```\n",
        "# Predict color image\n",
        "output = model.predict(gray_input)[0]\n",
        "output = np.clip(output * 255, 0, 255).astype(\"uint8\")\n",
        "output_resized = cv2.resize(output, (input_img.shape[1], input_img.shape[0]))\n",
        "return output_resized\n",
        "\n",
        "```\n",
        "\n",
        "# Launch Gradio UI\n",
        "\n",
        "gr.Interface(\n",
        "fn=colorize_image,\n",
        "inputs=gr.Image(type=\"numpy\", label=\"Upload Grayscale Image\"),\n",
        "outputs=gr.Image(type=\"numpy\", label=\"Colorized Image\"),\n",
        "title=\"Black & White to Color Image Colorization\"\n",
        ").launch()"
      ],
      "metadata": {
        "id": "BNlSbOi9-FJN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}